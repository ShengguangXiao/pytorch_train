{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time, shutil, os, cv2\n",
    "from torchvision import transforms\n",
    "from ClassicNetwork.ResNet import ResNet50\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    bz, nc, h, w = feature_conv.shape        #1,2048,7,7\n",
    "    output_cam = []\n",
    "    for idx in class_idx:  #只输出预测概率最大值结果不需要for循环\n",
    "        feature_conv = feature_conv.reshape((nc, h*w))\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))  #(2048, ) * (2048, 7*7) -> (7*7, ) （n,）是一个数组，既不是行向量也不是列向量\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam_img = (cam - cam.min()) / (cam.max() - cam.min())  #Normalize\n",
    "        cam_img = np.uint8(255 * cam_img)                      #Format as CV_8UC1 (as applyColorMap required)\n",
    "\n",
    "        #output_cam.append(cv2.resize(cam_img, size_upsample))  # Resize as image size\n",
    "        output_cam.append(cam_img)\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_path = '/Users/shengguang.xiao/GitHub/pytorch_train/OcvData_Resnet/Valid_Set/class_bad'\n",
    "# File_name = '_A8D48549-C49C-4284-9091-C5F60CB75058_Region1_r0_c0.jpg'\n",
    "\n",
    "CAM_RESULT_PATH = os.path.join(File_path, 'CAMs')   #CAM结果的存储地址\n",
    "os.makedirs(CAM_RESULT_PATH, exist_ok=True)\n",
    "os.makedirs(CAM_RESULT_PATH +'/0', exist_ok=True)\n",
    "os.makedirs(CAM_RESULT_PATH +'/1', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label  = {\"0\": 0, \"1\": 1}\n",
    "class_ = ['Good', 'Bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path,  bad_image_2.png\n",
      "torch.Size([1, 4, 41, 47])\n",
      "torch.Size([1, 3, 41, 47])\n",
      "tensor([0.9998], grad_fn=<MaxBackward0>) tensor([1])\n",
      "time cost =  0.04476428031921387\n",
      "fc_wights [[ 0.02675873 -0.00400169  0.02323121 ...  0.01285838 -0.0143756\n",
      "  -0.02610539]\n",
      " [-0.00191292  0.02722661 -0.01338094 ... -0.00010555  0.008932\n",
      "  -0.01079006]]\n",
      "File Path,  bad_image_1.png\n",
      "torch.Size([1, 4, 41, 47])\n",
      "torch.Size([1, 3, 41, 47])\n",
      "tensor([0.9808], grad_fn=<MaxBackward0>) tensor([1])\n",
      "time cost =  0.019250869750976562\n",
      "fc_wights [[ 0.02675873 -0.00400169  0.02323121 ...  0.01285838 -0.0143756\n",
      "  -0.02610539]\n",
      " [-0.00191292  0.02722661 -0.01338094 ... -0.00010555  0.008932\n",
      "  -0.01079006]]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = ResNet50(num_classes=len(label), imgsz=64)\n",
    "model = model.to(device)\n",
    "\n",
    "#### load model\n",
    "pth        = './Results/Resnet_100.0_epoch_22.pt'\n",
    "checkpoint = torch.load(pth)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "#### load model to last feature map to create CAM feature (Classification Activation Map)\n",
    "model_features = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "model.eval()\n",
    "model_features.eval()\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(),])\n",
    "f1    = nn.Softmax(dim=1)\n",
    "\n",
    "for File_name in os.listdir(File_path):\n",
    "    if File_name.endswith('.png'):\n",
    "        print(\"File Path, \", File_name)\n",
    "\n",
    "        ## open image and transform to tensor\n",
    "        imgt = Image.open(os.path.join(File_path, File_name))\n",
    "        img  = trans(imgt)\n",
    "        img  = img[None]\n",
    "\n",
    "        img = img.float().to(device)\n",
    "        #img = torch.rand(1, 3, 47, 41)\n",
    "        print(img.shape)\n",
    "\n",
    "        img = img[:,[0,1,2],:,:] # select rgb but not the alpha\n",
    "\n",
    "        print(img.shape)\n",
    "\n",
    "        ## model predict\n",
    "        start_time = time.time()\n",
    "        out = model(img)    #前向算法\n",
    "        out = f1(out)\n",
    "        conf, pred = torch.max(out,1)   #预测结果\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(\"conf \", conf, \" pred \", pred)\n",
    "        print('time cost = ', end_time - start_time)\n",
    "\n",
    "        ### get feature map\n",
    "        features   = model_features(img).detach().cpu().numpy() \n",
    "        fc_weights = model.state_dict()['fc.weight'].cpu().numpy()\n",
    "        print(\"fc_wights\", fc_weights)\n",
    "\n",
    "        # print(features.shape)\n",
    "        # print(fc_weights.shape)\n",
    "\n",
    "        CAMs = returnCAM(features, fc_weights, pred)  #输出预测概率最大的特征图集对应的CAM\n",
    "        # print(img_name + ' output for the top1 prediction: %s' % class_[idx[0]])\n",
    "\n",
    "        #img  = cv2.imread(os.path.join(File_path, File_name))\n",
    "        imgt = cv2.cvtColor(np.asarray(imgt),cv2.COLOR_RGB2BGR) \n",
    "        height, width, _ = imgt.shape  #读取输入图片的尺寸\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)  #CAM resize match input image size\n",
    "        result = heatmap * 0.3 + imgt * 0.5    #比例可以自己调节\n",
    "\n",
    "        text = '%s %.2f%%' % (class_[pred], conf[0]*100) \t\t\t\t #激活图结果上的文字显示\n",
    "        cv2.putText(result, text, (20, height-10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.9,\n",
    "                    color=(123, 222, 238), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        image_name_ = File_name[:-4]\n",
    "\n",
    "        if pred == 0:\n",
    "            cv2.imwrite(CAM_RESULT_PATH + '/0/' + image_name_ + '_pred_' + class_[pred] + '.jpg', result)  #写入存储磁盘\n",
    "        else:\n",
    "            cv2.imwrite(CAM_RESULT_PATH + '/1/' + image_name_ + '_pred_' + class_[pred] + '.jpg', result)  #写入存储磁盘\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
